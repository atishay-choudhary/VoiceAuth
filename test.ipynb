{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_device\u001b[39m():\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def check_device():\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"CUDA-compatible GPU found, using GPU.\")\n",
    "    else:\n",
    "        print(\"No CUDA-compatible GPU found, using CPU.\")\n",
    "\n",
    "check_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwave\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "import joblib\n",
    "import librosa\n",
    "import librosa.display\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml.svm import SVC\n",
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Path to dataset\n",
    "DATASET_PATH = r\"C:\\Users\\atish\\Documents\\VoiceAuth\\Audios\\user_0\"\n",
    "\n",
    "# ----- Audio Preprocessing -----\n",
    "def record_audio(duration=3, fs=44100, filename=\"temp.wav\"):\n",
    "    \"\"\"Records audio from the microphone and saves it as a WAV file.\"\"\"\n",
    "    try:\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=pyaudio.paInt16, channels=1, rate=fs, input=True, frames_per_buffer=1024)\n",
    "        print(\"üé§ Recording...\")\n",
    "\n",
    "        frames = [stream.read(1024) for _ in range(0, int(fs / 1024 * duration))]\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        wf = wave.open(filename, \"wb\")\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "\n",
    "        with wave.open(filename, \"rb\") as wf:\n",
    "            audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "\n",
    "        return audio.astype(np.float32), fs\n",
    "    except Exception as e:\n",
    "        print(f\"Recording error: {e}\")\n",
    "        return np.array([]), fs\n",
    "\n",
    "# ----- Feature Extraction -----\n",
    "def butter_lowpass_filter(data, cutoff=3000, fs=44100, order=5):\n",
    "    \"\"\"Applies a low-pass filter to remove high-frequency noise.\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def extract_features(audio, fs):\n",
    "    \"\"\"Extracts advanced audio features for authentication.\"\"\"\n",
    "    try:\n",
    "        audio = butter_lowpass_filter(audio)\n",
    "        audio, _ = librosa.effects.trim(audio, top_db=40)\n",
    "        n_fft = 1024 if len(audio) >= 512 else 512\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=13, n_fft=n_fft)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=fs, n_fft=n_fft)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=fs, n_fft=n_fft)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio), sr=fs)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=fs, n_fft=n_fft)\n",
    "        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "        features = np.hstack([\n",
    "            np.mean(mfccs, axis=1), np.mean(chroma, axis=1), np.mean(spectral_contrast, axis=1), \n",
    "            np.mean(tonnetz, axis=1), np.mean(mel_spec, axis=1), np.mean(delta_mfccs, axis=1)\n",
    "        ])\n",
    "        return cp.array(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction error: {e}\")\n",
    "        return cp.zeros(169)\n",
    "\n",
    "# ----- Model Training -----\n",
    "def train_voice_model():\n",
    "    \"\"\"Trains an SVM voice authentication model using GPU.\"\"\"\n",
    "    user_samples = []\n",
    "    for file in os.listdir(DATASET_PATH):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(DATASET_PATH, file)\n",
    "            with wave.open(file_path, \"rb\") as wf:\n",
    "                audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "                fs = wf.getframerate()\n",
    "            user_samples.append(extract_features(audio, fs))\n",
    "    \n",
    "    impostor_samples = [cp.random.randn(169) for _ in range(len(user_samples))]\n",
    "    X = cp.vstack((user_samples, impostor_samples))\n",
    "    y = cp.array([1] * len(user_samples) + [0] * len(impostor_samples))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    grid = GridSearchCV(SVC(probability=True), param_grid, cv=3)\n",
    "    grid.fit(X_train, y_train)\n",
    "    model = grid.best_estimator_\n",
    "    print(f\"‚úÖ Training Accuracy: {model.score(X_test, y_test) * 100:.2f}%\")\n",
    "    joblib.dump(model, \"voice_auth_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    return model, scaler\n",
    "\n",
    "# ----- Authentication -----\n",
    "def authenticate_voice():\n",
    "    \"\"\"Authenticates a user using GPU-accelerated SVM.\"\"\"\n",
    "    try:\n",
    "        model = joblib.load(\"voice_auth_model.pkl\")\n",
    "        scaler = joblib.load(\"scaler.pkl\")\n",
    "        audio, fs = record_audio(3)\n",
    "        features = extract_features(audio, fs)\n",
    "        if cp.count_nonzero(features) == 0:\n",
    "            print(\"‚ùå Invalid audio input, please try again!\")\n",
    "            return\n",
    "        features = scaler.transform(features.reshape(1, -1))\n",
    "        prediction = model.predict(features)[0]\n",
    "        probability = model.predict_proba(features)[0][int(prediction)] * 100\n",
    "        if prediction == 1 and probability >= 90:\n",
    "            print(f\"‚úÖ Access Granted (Confidence: {probability:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Access Denied (Confidence: {probability:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Authentication error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, scaler = train_voice_model()\n",
    "    authenticate_voice()\n",
    "    os.remove(\"temp.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
